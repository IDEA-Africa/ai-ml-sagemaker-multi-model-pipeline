{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d831a62",
   "metadata": {},
   "source": [
    "## Prepare Athena table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cca89c",
   "metadata": {},
   "source": [
    "At this point, it is assumed that S3 bucket sagemaker-restate-`<AWS ACCOUNT ID>` is created and raw data has been uploaded to s3://sagemaker-restate-`<AWS ACCOUNT ID>`/raw/california/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e353f7",
   "metadata": {},
   "source": [
    "The step below creates a Glue database and table containing the raw data by running a Glue crawler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b36b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "AWS_ACCOUNT = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "\n",
    "BUCKET_NAME = \"sagemaker-restate-{AWS_ACCOUNT}\".format(AWS_ACCOUNT=AWS_ACCOUNT)\n",
    "DATABASE_NAME = 'restate'\n",
    "TABLE_NAME = 'california'\n",
    "\n",
    "glue_client = boto3.client('glue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = glue_client.create_database(\n",
    "        DatabaseInput={\n",
    "            'Name': DATABASE_NAME\n",
    "        }\n",
    "    )\n",
    "    print(\"Successfully created database\")\n",
    "except Exception as e:\n",
    "    print('Error in creating database: {ERROR}'.format(ERROR=e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c08098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes the Glue service role name is AWSGlueServiceRole-restate\n",
    "try:\n",
    "    response = glue_client.create_crawler(\n",
    "        Name= \"{DATABASE_NAME}-{TABLE_NAME}\".format(DATABASE_NAME=DATABASE_NAME, TABLE_NAME=TABLE_NAME),\n",
    "        Role='AWSGlueServiceRole-restate',\n",
    "        DatabaseName=DATABASE_NAME,\n",
    "        Targets={\n",
    "            'S3Targets': [\n",
    "                {\n",
    "                    'Path': 's3://{BUCKET_NAME}/raw/california/'.format(BUCKET_NAME=BUCKET_NAME),\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    print(\"Successfully created crawler\")\n",
    "except Exception as e:\n",
    "    print('Error in creating crawler: {ERROR}'.format(ERROR=e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = glue_client.start_crawler(\n",
    "        Name=\"{DATABASE_NAME}-{TABLE_NAME}\".format(DATABASE_NAME=DATABASE_NAME, TABLE_NAME=TABLE_NAME)\n",
    "    )\n",
    "    print(\"Successfully started crawler\")\n",
    "except Exception as e:\n",
    "    print('Error in starting crawler: {ERROR}'.format(ERROR=e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acdbdbb",
   "metadata": {},
   "source": [
    "Once crawler is done crawling, table `california` in database `restate` should be visible in Glue catalog. We rename tne Glue table columns for readability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3032f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = glue_client.get_table(DatabaseName=DATABASE_NAME,Name=TABLE_NAME)\n",
    "glue_table = response['Table']\n",
    "glue_table['StorageDescriptor']['Columns'][0]['Name'] = 'longitude'\n",
    "glue_table['StorageDescriptor']['Columns'][1]['Name'] = 'latitude'\n",
    "glue_table['StorageDescriptor']['Columns'][2]['Name'] = 'housingMedianAge'\n",
    "glue_table['StorageDescriptor']['Columns'][3]['Name'] = 'totalRooms'\n",
    "glue_table['StorageDescriptor']['Columns'][4]['Name'] = 'totalBedrooms'\n",
    "glue_table['StorageDescriptor']['Columns'][5]['Name'] = 'population'\n",
    "glue_table['StorageDescriptor']['Columns'][6]['Name'] = 'households'\n",
    "glue_table['StorageDescriptor']['Columns'][7]['Name'] = 'medianIncome'\n",
    "glue_table['StorageDescriptor']['Columns'][8]['Name'] = 'medianHouseValue'\n",
    "glue_client.update_table(DatabaseName=DATABASE_NAME,TableInput={'Name': TABLE_NAME, 'StorageDescriptor':glue_table['StorageDescriptor']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a4243d",
   "metadata": {},
   "source": [
    "Table `california` in database `restate` should be visible in Athena. We filter only the data where housingmedianage > 10. \n",
    "\n",
    "Make sure Athena query result location setting is updated accordingly before proceeding to the next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'CREATE TABLE restate.california_10 AS SELECT * FROM restate.california where housingmedianage > 10;'\n",
    "output='s3://{BUCKET_NAME}/athena'.format(BUCKET_NAME=BUCKET_NAME)\n",
    "\n",
    "athena_client = boto3.client('athena')\n",
    "\n",
    "try:\n",
    "    response = athena_client.start_query_execution(\n",
    "        QueryString=query,\n",
    "        QueryExecutionContext={\n",
    "            'Database': DATABASE_NAME\n",
    "        },\n",
    "        ResultConfiguration={\n",
    "            'OutputLocation': output,\n",
    "        }\n",
    "    )\n",
    "except Exception as e:\n",
    "    print('Error running the query: {ERROR}'.format(ERROR=e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bbd36a",
   "metadata": {},
   "source": [
    "## Prepare Decision Tree custom Docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90facab6",
   "metadata": {},
   "source": [
    "We make a  Docker image containing a custom algorithm using [Scikit-learn Decision Tree Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor). Note that the Docker image has been modified to support hyperparameter tuning and validation data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d175e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo yum install docker -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "ALGORITHM_NAME=restate-decision-trees\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x decision_trees/train\n",
    "chmod +x decision_trees/serve\n",
    "\n",
    "AWS_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "AWS_REGION=$(aws configure get region)\n",
    "\n",
    "IMAGE_FULLNAME=\"${AWS_ACCOUNT}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ALGORITHM_NAME}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${ALGORITHM_NAME}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${ALGORITHM_NAME}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${AWS_REGION}|docker login --username AWS --password-stdin ${IMAGE_FULLNAME}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${ALGORITHM_NAME} .\n",
    "docker tag ${ALGORITHM_NAME} ${IMAGE_FULLNAME}\n",
    "docker push ${IMAGE_FULLNAME}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1288b23",
   "metadata": {},
   "source": [
    "Once Docker image is pushed to ECR repository, we make the image accessible from SageMaker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ccf1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "SM_IMAGE_NAME=restate-dtree\n",
    "AWS_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# This assumes the role name is AmazonSageMakerServiceCatalogProductsUseRole-restate\n",
    "ROLE_ARN=\"arn:aws:iam::${AWS_ACCOUNT}:role/AmazonSageMakerServiceCatalogProductsUseRole-restate\"\n",
    "\n",
    "aws sagemaker create-image \\\n",
    "    --image-name ${SM_IMAGE_NAME} \\\n",
    "    --role-arn ${ROLE_ARN}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "AWS_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)\n",
    "ALGORITHM_NAME=restate-decision-trees\n",
    "AWS_REGION=$(aws configure get region)\n",
    "SM_IMAGE_NAME=restate-dtree\n",
    "SM_BASE_IMAGE=\"${AWS_ACCOUNT}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ALGORITHM_NAME}:latest\"\n",
    "\n",
    "aws sagemaker create-image-version \\\n",
    "    --image-name ${SM_IMAGE_NAME} \\\n",
    "    --base-image ${SM_BASE_IMAGE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee2de0",
   "metadata": {},
   "source": [
    "Make sure to update the `SM_BASE_IMAGE_VERSION` below with the correct one based on the output of the previous step, i.e. `...image-version/restate-dtree/<SM_BASE_IMAGE_VERSION>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14786d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "SM_BASE_IMAGE_VERSION=1\n",
    "AWS_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)\n",
    "ALGORITHM_NAME=restate-decision-trees\n",
    "AWS_REGION=$(aws configure get region)\n",
    "SM_IMAGE_NAME=restate-dtree\n",
    "SM_BASE_IMAGE=\"${AWS_ACCOUNT}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ALGORITHM_NAME}:latest\"\n",
    "\n",
    "aws sagemaker describe-image-version \\\n",
    "    --image-name ${SM_IMAGE_NAME} \\\n",
    "    --version ${SM_BASE_IMAGE_VERSION}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c9e0ad",
   "metadata": {},
   "source": [
    "## Start the SageMaker pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a315c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sagemaker-pipeline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1a7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! get-pipeline-definition --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a443b3b",
   "metadata": {},
   "source": [
    "At this point, it is assumed that a SageMaker project with a name `restate` and a pipeline with a name `sagemaker-restate` are already created. Replace `<SAGEMAKER_PROJECT_ID>` with the appropriate SageMaker project ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# This assumes the SageMaker pipeline role name is AmazonSageMakerServiceCatalogProductsUseRole-restate\n",
    "\n",
    "AWS_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)\n",
    "AWS_REGION=$(aws configure get region)\n",
    "SAGEMAKER_PROJECT_NAME=restate\n",
    "SAGEMAKER_PROJECT_ID=<SAGEMAKER_PROJECT_ID>\n",
    "SAGEMAKER_PROJECT_ARN=\"arn:aws:sagemaker:${AWS_REGION}:${AWS_ACCOUNT}:project/${SAGEMAKER_PROJECT_NAME}\"\n",
    "SAGEMAKER_PIPELINE_ROLE_ARN=\"arn:aws:iam::${AWS_ACCOUNT}:role/AmazonSageMakerServiceCatalogProductsUseRole-restate\"\n",
    "SAGEMAKER_PIPELINE_NAME=\"sagemaker-${SAGEMAKER_PROJECT_NAME}\"\n",
    "ARTIFACT_BUCKET=\"sagemaker-project-${SAGEMAKER_PROJECT_ID}\"\n",
    "SAGEMAKER_PROJECT_NAME_ID=\"${SAGEMAKER_PROJECT_NAME}-${SAGEMAKER_PROJECT_ID}\"\n",
    "\n",
    "run-pipeline --module-name pipelines.restate.pipeline \\\n",
    "  --role-arn $SAGEMAKER_PIPELINE_ROLE_ARN \\\n",
    "  --tags \"[{\\\"Key\\\":\\\"sagemaker:project-name\\\", \\\"Value\\\":\\\"${SAGEMAKER_PROJECT_NAME}\\\"}, {\\\"Key\\\":\\\"sagemaker:project-id\\\", \\\"Value\\\":\\\"${SAGEMAKER_PROJECT_ID}\\\"}]\" \\\n",
    "  --kwargs \"{\\\"region\\\":\\\"${AWS_REGION}\\\",\\\"sagemaker_project_arn\\\":\\\"${SAGEMAKER_PROJECT_ARN}\\\",\\\"role\\\":\\\"${SAGEMAKER_PIPELINE_ROLE_ARN}\\\",\\\"default_bucket\\\":\\\"${ARTIFACT_BUCKET}\\\",\\\"pipeline_name\\\":\\\"${SAGEMAKER_PROJECT_NAME_ID}\\\",\\\"model_package_group_name\\\":\\\"${SAGEMAKER_PROJECT_NAME_ID}\\\",\\\"base_job_prefix\\\":\\\"${SAGEMAKER_PROJECT_NAME_ID}\\\"}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11721d2e",
   "metadata": {},
   "source": [
    "If you inspect the pipeline, you will see that the XGBoost model performs better than Decision Tree. Therefore, the XGBoost model is registered in the registry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac149e",
   "metadata": {},
   "source": [
    "You can experiment on the data, e.g. use data for `housingmedianage > 50`, by changing the Athena query in `pipeline.py`. See if using this data, XGBoost would still be the winning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b21afe",
   "metadata": {},
   "source": [
    "## Deploy the winning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a3b35e",
   "metadata": {},
   "source": [
    "Make sure to update `MODEL_VERSION`, `SAGEMAKER_PROJECT_NAME`, and `SAGEMAKER_PROJECT_ID`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role, session\n",
    "import boto3\n",
    "\n",
    "role = get_execution_role()\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "\n",
    "MODEL_VERSION=\"1\"\n",
    "SAGEMAKER_PROJECT_NAME=\"restate-4\"\n",
    "SAGEMAKER_PROJECT_ID=\"p-efaus2jukpna\"\n",
    "AWS_REGION = boto3.Session().region_name\n",
    "MODEL_PACKAGE_ARN=\"arn:aws:sagemaker:{AWS_REGION}:{AWS_ACCOUNT}:model-package/{SAGEMAKER_PROJECT_NAME}-{SAGEMAKER_PROJECT_ID}/{MODEL_VERSION}\".format(AWS_REGION=AWS_REGION, AWS_ACCOUNT=AWS_ACCOUNT, SAGEMAKER_PROJECT_NAME=SAGEMAKER_PROJECT_NAME,SAGEMAKER_PROJECT_ID=SAGEMAKER_PROJECT_ID,MODEL_VERSION=MODEL_VERSION)\n",
    "                    \n",
    "\n",
    "model_package_update_response = sm_client.update_model_package(\n",
    "    ModelPackageArn=MODEL_PACKAGE_ARN,\n",
    "    ModelApprovalStatus=\"Approved\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea518ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = 'restate-modelregistry-model-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model name : {}\".format(model_name))\n",
    "container_list = [{'ModelPackageName': MODEL_PACKAGE_ARN}]\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers = container_list\n",
    ")\n",
    "print(\"Model arn : {}\".format(create_model_response[\"ModelArn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = 'restate-modelregistry-EndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m5.large',\n",
    "        'InitialVariantWeight':1,\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af1db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'restate-modelregistry-endpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "print(create_endpoint_response['EndpointArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ad6fa",
   "metadata": {},
   "source": [
    "Wait for the endpoint to be created. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90de3d",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992fd2fa",
   "metadata": {},
   "source": [
    "Use the following data for inference:\n",
    "\n",
    "`-117.18,32.75,52.0,1504.0,208.0,518.0,196.0`\n",
    "\n",
    "This is a census block group with longitude -117.18, latitude 32.75, housing median age of 52.0, total rooms of 1504, total bedrooms of 208, population of 518, and households count of 196.\n",
    "\n",
    "Let's see its predicted value using our generated model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2036af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "sm_runtime= boto3.client('runtime.sagemaker')\n",
    "line = '-117.18,32.75,52.0,1504.0,208.0,518.0,196.0'\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='text/csv',\n",
    "    Body=line\n",
    ")\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2956c",
   "metadata": {},
   "source": [
    "Now you try:\n",
    "\n",
    "`-117.17,32.76,45.0,3149.0,639.0,1160.0,661.0`\n",
    "\n",
    "This is a census block group with longitude -117.17, latitude 32.76, housing median age of 45.0, total rooms of 3149, total bedrooms of 639, population of 1160, and households count of 661.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec405e",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c684e5de",
   "metadata": {},
   "source": [
    "Cleanup the Glue database, table, crawler, and S3 buckets used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f94d87",
   "metadata": {},
   "source": [
    "Cleanup the ECR and SageMaker images created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed60fff4",
   "metadata": {},
   "source": [
    "Cleanup the SageMaker model and endpoint resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_latest_p37",
   "language": "python",
   "name": "conda_mxnet_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
